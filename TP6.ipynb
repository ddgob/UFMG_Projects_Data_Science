{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# -*- coding: utf-8 -*-\n", "\"\"\"Lista06.ipynb"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Automatically generated by Colaboratory."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Original file is located at\n", "    https://colab.research.google.com/drive/1dLh2FgpbNFUlAesnBmGHHGyRb9QcJ7DU"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Lista 6 - Teorema Central do Limite, ICs e Testes de Hip\u00f3teses"]}, {"cell_type": "markdown", "metadata": {}, "source": [" Teorema Central do Limite e Distribui\u00e7\u00e3o Normal"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["**Conceito:** A distribui\u00e7\u00e3o das m\u00e9dias de vari\u00e1veis aleat\u00f3rias independentes e identicamente distribu\u00eddas segue a uma Normal."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Vamos fazer um experimento cl\u00e1ssico para demonstrar na pr\u00e1tica."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["- Geraremos $n$ amostras de tamanho 100 de uma distribui\u00e7\u00e3o qualquer (utilizaremos uma Uniforme, mas funciona para qualquer distribui\u00e7\u00e3o).\n", "- Calcularemos suas m\u00e9dias.\n", "- Plotamos um histograma.\n", "- Variaremos o tamanho de $n$ e repetiremos."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Vamos usar:\n", "- $n=10$\n", "- $n=20$\n", "- $n=50$\n", "- $n=100$\n", "- $n=1000$\n", "\"\"\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from numpy.testing import assert_almost_equal\n", "from numpy.testing import assert_equal\n", "from numpy.testing import assert_array_almost_equal\n", "from numpy.testing import assert_array_equal\n", "np.random.seed(23) # seed para reprodutibilidade"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["size = 100"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["medias = []\n", "for n in [10, 20, 50, 100, 1000]:\n", "  for _ in range(n):\n", "    data = np.random.uniform(1, 1000, size)\n", "    medias.append(data.mean())\n", "  plt.hist(medias, bins=15, rwidth=0.95)\n", "  plt.title('N={}'.format(n))\n", "  plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\nNote que a medida que aumentamos o n\u00famero de m\u00e9dias amostradas ($n$), o histograma fica cada vez mais similar a uma distribui\u00e7\u00e3o Normal.<br>\n", "**Est\u00e1 demonstrado o princ\u00edpio do Teorema Central do Limite!**<br>\n", "Ao demonstrar o TCL, mostramos indiretamente porque a distribui\u00e7\u00e3o Normal \u00e9 t\u00e3o importante. Vamos agora, revisar e explorar a Normal um pouco mais.<br>\n", "Se as m\u00e9dias de vari\u00e1veis aleat\u00f3rias apresentam distribui\u00e7\u00e3o pr\u00f3xima a Normal, como podemos estimar probabilidades e fazer testes com base na Normal?<br>\n", "Uma distribui\u00e7\u00e3o Normal \u00e9 definida por dois par\u00e2metros:<br>\n", "- M\u00e9dia ($\\mu$).<br>\n", "- Desvio padr\u00e3o ($\\sigma$), ou vari\u00e2ncia ($\\sigma^2$).<br>\n", "Tendo esses valores de uma popula\u00e7\u00e3o e uma amostra com $n$ elementos, podemos normaliz\u00e1-la de forma que os valores resultantes possuam uma distribui\u00e7\u00e3o Normal Gaussiana, ou seja, com $\\mu=0$ e $\\sigma^2=1$, denotada por Normal(0,1), ou ainda, N(0,1). Para fazer isso, utilizamos:<br>\n", "$$ Z = \\frac {\\bar X-\\mu}{\\sigma/\\sqrt{n}}, $$<br>\n", "onde:<br>\n", "- $\\bar{X}$: \u00e9 a m\u00e9dia encontrada em uma amostra de tamanho $n$.<br>\n", "- $\\mu$: \u00e9 a m\u00e9dia da popula\u00e7\u00e3o da qual realizamos a amostra.<br>\n", "- $\\sigma^2$: \u00e9 a vari\u00e2ncia da popula\u00e7\u00e3o da qual realizamos a amostra.<br>\n", "Assim, temos:<br>\n", "$$Z \\thicksim Normal(0,1)$$<br>\n", "Lembre-se que tamb\u00e9m sabemos que a vari\u00e2ncia do estimador da m\u00e9dia \u00e9:<br>\n", "$$Var(\\hat{\\mu}) = \\frac{\\sigma^2}{n}$$<br>\n", "Assim:<br>\n", "$$\\bar{X} \\thicksim Normal\\left(\\mu, \\frac{\\sigma^2}{n}\\right)$$<br>\n", "A Normal Gaussiana \u00e9 de extrema import\u00e2ncia, pois serve de base para definirmos probabilidades. Vamos ver um exemplo.<br>\n", "**Exemplo:** Dado que a popula\u00e7\u00e3o de homens de um pa\u00eds apresenta pesos distribu\u00eddos normalmente com m\u00e9dia de 173lb e desvio-padr\u00e3o de 30lb. Como podemos determinar a probabilidade de um homem escolhido aleatoriamente pesar mais de 180lb?<br>\n", "Nesse caso, temos:<br>\n", "- $\\mu = 173$<br>\n", "- $\\sigma = 30$<br>\n", "- $n = 1$<br>\n", "Vamos encontrar o valor de Z.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def z_obs(x, mu, sigma, n):\n", "  z = (x - mu)/(sigma/np.sqrt(n))\n", "  return z.round(2)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["z_obs(180, 173, 30, 1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\nSabemos que $z$ \u00e9 um valor de uma distribui\u00e7\u00e3o Normal com m\u00e9dia 0 e vari\u00e2ncia 1.<br>\n", "Vamos ent\u00e3o encontrar a probabilidade de obtermos um valor maior que $z$.<br>\n", "Para isso, estat\u00edsticos usam uma tabela com as probabilidades bem definidas. Cientistas de dados fazem assim:<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import scipy.stats as ss"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(ss.distributions.norm.sf(0.23))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\nIsso nos diz que a probabilidade de obtermos um valor maior que o valor de $z$ encontrado (0.23), na distribui\u00e7\u00e3o Normal(0,1) \u00e9 0.4090!<br>\n", "Logo, a probabilidade de um homem selecionado aleatoriamente pesar mais que 180lb \u00e9 0.4090!<br>\n", "E se quisermos calcular a probabilidade do peso m\u00e9dio de 36 homens selecionados aleatoriamente ser maior que 180lb?<br>\n", "A ideia \u00e9 a mesma.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(z_obs(180, 173, 30, 36))\n", "print(ss.distributions.norm.sf(z_obs(180, 173, 30, 36)))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\nConclu\u00edmos que h\u00e1 uma probabilidade de 0.4090 de UM indiv\u00edduo pesar mais que 180, por\u00e9m a probabilidade da m\u00e9dia do peso de 36 homens \u00e9 de apenas 0.0808.<br>\n", "**\u00c9 muito mais f\u00e1cil um indiv\u00edduo se afastar da m\u00e9dia, do que um grupo com 36 indiv\u00edduos.**<br>\n", "Note que escancaramos a influ\u00eancia do tamanho da amostra. Para uma mesma distribui\u00e7\u00e3o com os mesmos par\u00e2metros, aumentar o tamanho da amostra significa se afastar da m\u00e9dia na distribui\u00e7\u00e3o Z (note que o valor de $z$ para o caso com $n=36$ \u00e9 superior ao caso com $n=1$ e a m\u00e9dia da distribui\u00e7\u00e3o de Z \u00e9 0), por\u00e9m significa que a probabilidade da m\u00e9dia dos pesos ser superior a 180lb \u00e9 muito menor.<br>\n", "## Exerc\u00edcio 1<br>\n", "Sabendo que os pre\u00e7os de bolsas de uma marca de grife seguem uma distribui\u00e7\u00e3o Normal com m\u00e9dia 1100 reais e desvio-padr\u00e3o de 420, altere o c\u00f3digo abaixo para retornar a probabilidade de uma bolsa selecionada aleatoriamente custar mais que 1400 reais.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def prob(x, mu, sigma, n):\n", "  numZ = (x - mu) / (sigma / np.sqrt(n))\n", "  return ss.distributions.norm.sf(numZ)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["p = prob(1400, 1100, 420, 1)\n", "assert_equal(0.2375, p.round(4))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n## Intervalos de Confian\u00e7a<br>\n", "Vimos duas maneiras de construirmos intervalos de confian\u00e7a para vari\u00e1veis aleat\u00f3rias:<br>\n", "- Usando o teorema central do limite.<br>\n", "- Usando *Bootstrap*.<br>\n", "Com baso no TCL e nas propriedades da distribui\u00e7\u00e3o Normal podemos definir intervalos de confian\u00e7a. Basta definirmos o n\u00edvel de confian\u00e7a associado ao nosso intervalo e manipularmos a equa\u00e7\u00e3o do TCL utilizada para encontrar $z$ de forma a isolar $\\mu$ (par\u00e2metro de interesse).<br>\n", "$$\\begin{align}<br>\n", "0.95 = P(-z \\le Z \\le z)=P \\left(-1.96 \\le \\frac {\\bar X-\\mu}{\\sigma/\\sqrt{n}} \\le 1.96 \\right) = P \\left( \\bar X - 1.96 \\frac \\sigma {\\sqrt{n}} \\le \\mu \\le \\bar X + 1.96 \\frac \\sigma {\\sqrt{n}}\\right),<br>\n", "\\end{align}$$<br>\n", "onde 1.96 \u00e9 o valor de $z$ associado ao n\u00edvel de confian\u00e7a escolhido. Basicamente \u00e9 o inverso do que est\u00e1vamos fazendo. Ao inv\u00e9s de encontrarmos a probabilidade associada a um valor $z$, encontramos o valor $z$ associado a uma probabilidade pr\u00e9-definida (n\u00edvel de confian\u00e7a).<br>\n", "## Exerc\u00edcio 2<br>\n", "**a) Qual a temperatura m\u00e9dia do corpo humano?**<br>\n", "Os dados a seguir foram obtidos por pesquisadores da Universidade de Maryland que mediram 106 temperaturas do corpo humano. Construa um intervalo de 95% de confian\u00e7a para a m\u00e9dia. Utilize a equa\u00e7\u00e3o acima.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data = np.array([98.6, 98.6, 98.0, 98.0, 99.0, 98.4, 98.4, 98.4, 98.4, 98.6, 98.6, \n", "                 98.8, 98.6, 97.0, 97.0, 98.8, 97.6, 97.7, 98.8, 98.0, 98.0, 98.3,\n", "                 98.5, 97.3, 98.7, 97.4, 98.9, 98.6, 99.5, 97.5, 97.3, 97.6, 98.2,\n", "                 99.6, 98.7, 99.4, 98.2, 98.0, 98.6, 98.6, 97.2, 98.4, 98.6, 98.2,\n", "                 98.0, 97.8, 98.0, 98.4, 98.6, 98.6, 97.8, 99.0, 96.5, 97.6, 98.0,\n", "                 96.9, 97.6, 97.1, 97.9, 98.4, 97.3, 98.0, 97.5, 97.6, 98.2, 98.5,\n", "                 98.8, 98.7, 97.8, 98.0, 97.1, 97.4, 99.4, 98.4, 98.6, 98.4, 98.5,\n", "                 98.6, 98.3, 98.7, 98.8, 99.1, 98.6, 97.9, 98.8, 98.0, 98.7, 98.5,\n", "                 98.9, 98.4, 98.6, 97.1, 97.9, 98.8, 98.7, 97.6, 98.2, 99.2, 97.8,\n", "                 98.0, 98.4, 97.8, 98.4, 97.4, 98.0, 97.0])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def ic(data):\n", "  n = 10000\n", "  averages = np.zeros(n)\n", "  for i in range(n):\n", "      average = np.random.choice(data, 100).mean()\n", "      averages[i] = average\n", "  LI = np.percentile(averages, 2.5)\n", "  LS = np.percentile(averages, 97.5)\n", "  return (LI, LS)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["(LI, LS) = ic(data)\n", "assert_equal(98.08, LI.round(2))\n", "assert_equal(98.32, LS.round(2))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n**b) Bootstrap**<br>\n", "Suponha que voc\u00ea tenha apenas as 15 primeiras observa\u00e7\u00f5es das temperaturas corporais. Um intervalo de confian\u00e7a com poucos dados pode n\u00e3o ser muito aconselh\u00e1vel, pois n\u00e3o h\u00e1 garantias de que a sua amostra seja de fato representativa da sua popula\u00e7\u00e3o. Para contornar esse tipo de empecilho, \u00e9 comum utilizarmos t\u00e9cnicas de amostragem que garantam estimativas confi\u00e1veis que reflitam a popula\u00e7\u00e3o de interesse. Uma das maneiras de realizarmos esse processo de amostragem \u00e9 chamado de *Bootstrap* e consiste em realizar sub-amostras da amostra dispon\u00edvel, com reposi\u00e7\u00e3o. Assim gera-se v\u00e1rias novas amostras com elementos que podem se repetir nessas novas amostras, mesmo que isso n\u00e3o ocorra na amostra original.<br>\n", "Nessa lista, n\u00e3o daremos muito enfoque na explica\u00e7\u00e3o do *Bootstrap*, apenas na revis\u00e3o. Caso precise relembrar o m\u00e9todo, sugerimos a revis\u00e3o das aulas e listas de exerc\u00edcios com *Bootstrap*.<br>\n", "ALTERE A FUN\u00c7\u00c3O ABAIXO PARA RETORNAR UM INTERVALO DE 95% DE CONFIAN\u00c7A PARA AS TEMPERATURAS CORPORAIS DOS 15 PRIMEIROS INDIV\u00cdDUOS. UTILIZE 5000 SUB-AMOSTRAS DE TAMANHO IGUAL AO TAMANHO ORIGINAL (15).<br>\n", "Voc\u00ea pode utilizar _np.random.seed(i)_ para controlar a aleatoriedade da i-\u00e9sima itera\u00e7\u00e3o.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = data[:15]\n", "def bootstrap_mean(x):\n", "  numRep = 5000\n", "  averages = np.zeros(numRep)\n", "  for i in np.arange(numRep):\n", "      np.random.seed(i)\n", "      average = np.random.choice(x, size=x.size).mean()\n", "      averages[i] = average\n", "  LI = np.percentile(averages, 2.5)\n", "  LS = np.percentile(averages, 97.5)\n", "  return (LI, LS)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["(LI, LS) = bootstrap_mean(df)\n", "assert_equal(97.97, LI.round(2))\n", "assert_equal(98.55, LS.round(2))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n## Testes de Hip\u00f3teses<br>\n", "At\u00e9 o momento, vimos como realizar testes de hip\u00f3teses atrav\u00e9s de algumas metodologias diferentes. Podemos citar:<br>\n", "- Testes A/B: comparamos intervalos de confian\u00e7a para o estimador da m\u00e9dia (mediana), ou da diferen\u00e7a de m\u00e9dias e analisamos o boxplot. Nesse caso, a cria\u00e7\u00e3o de intervalos de confian\u00e7a pode ser via *bootstrap* ou via TLC.<br>\n", "- Testes de Permuta\u00e7\u00e3o: embaralhamos a amostra retirando a influ\u00eancia de uma vari\u00e1vel categ\u00f3rica e comparamos se a m\u00e9dia se mant\u00e9m.<br>\n", "Utilizando o conhecimento sobre testes de hip\u00f3teses, resolva as quest\u00f5es com o dataset a seguir.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data = pd.read_csv('https://raw.githubusercontent.com/rashida048/Datasets/master/home_data.csv', nrows=100)\n", "data.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n## Exerc\u00edcio 3<br>\n", "Uma corretora de im\u00f3veis desconfia que exista uma diferen\u00e7a entre os pre\u00e7os m\u00e9dios de casas de acordo com o n\u00famero de pisos (`floors`). Ela deseja comparar casas totalmente t\u00e9rreas (1 piso) e casas com mais de 1 piso. Realize um teste de permuta\u00e7\u00e3o, respondendo as quest\u00f5es. <br>\n", "1 - Definida as hip\u00f3teses:<br>\n", "$$H_0: \\mu_{T} = \\mu_{\\bar{T}}$$<br>\n", "$$H_1: \\mu_{T} \\neq \\mu_{\\bar{T}}$$<br>\n", "**2 - Qual a estat\u00edstica de teste?**<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def t_obs(data):\n", "  andar1 = data[\"floors\"] == 1\n", "  return data[andar1][\"price\"].mean() - data[~andar1][\"price\"].mean()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["tobs = t_obs(data)\n", "assert_equal(-53396.48, round(tobs, 2))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n**3 - Fa\u00e7a o processo de shuffling e responda: H\u00e1 diferen\u00e7a de pre\u00e7o significativa entre casas t\u00e9rreas e casas com mais de um andar?**\n<br>\n", "def shuffling(data: pd.DataFrame):<br>\n", "    andar1 = data[\"floors\"] == 1<br>\n", "    numRep = 5000<br>\n", "    diffs = np.zeros(numRep)<br>\n", "    for i in range(numRep):<br>\n", "        np.random.seed(i)<br>\n", "        np.random.shuffle(andar1.values)<br>\n", "        diffs[i] = data[andar1][\"price\"].mean() - data[~andar1][\"price\"].mean()<br>\n", "    LI = np.percentile(diffs, 2.5)<br>\n", "    LS = np.percentile(diffs, 97.5)<br>\n", "    return (LI, LS)<br>\n", "(c_inf, c_sup) = shuffling(data)<br>\n", "assert_equal(c_inf < -116000, True)<br>\n", "assert_equal(c_sup > 116000, True)<br>\n", "or fim, conclua: H\u00e1 diferen\u00e7a entre os pre\u00e7os de casas t\u00e9rreas e casas n\u00e3o t\u00e9rreas?\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def diffs():\n", "    andar1 = data[\"floors\"] == 1\n", "    numRep = 5000\n", "    diffs = np.zeros(numRep)\n", "    for i in range(numRep):\n", "        np.random.seed(i)\n", "        np.random.shuffle(andar1.values)\n", "        diffs[i] = data[andar1][\"price\"].mean() - data[~andar1][\"price\"].mean()\n", "    return diffs"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def pValor(t_obs, diffs):\n", "    return np.count_nonzero(diffs > t_obs) / diffs.size"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def resposta():\n", "  diff = diffs()\n", "  p = pValor(tobs, diff)\n", "  return p <= 0.05"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["assert_equal(resposta(), False)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}